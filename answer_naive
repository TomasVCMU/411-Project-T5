#!/usr/bin/python3 -W ignore::DeprecationWarning
# -*- coding: utf-8 -*-
"""word similarity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VkFsNTVDGtkk5dBg_REQ1qRN4TZ-HYOi
"""

import pandas as pd
import sys
import spacy
import re
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer


# verbose = True
verbose = True

# load spacy model
nlp = spacy.load('en_core_web_sm')


"""# Question Classification"""

def question_type(q):
  regexp = re.compile('(?i)what|how|which|where|when|who|whom|whose|why')
  if regexp.search(q):
    return 'wh-h'
  else:
    return 'binary'

"""## Word Embedding with TF-idf"""

class tfidf_sim():

  def get_sentence(self, context):
    doc = re.sub(r'==* .*==*', ' ', context)
    doc = doc.lower()
    pattern = '(?<!\d)(\.)|\.\n|\. '
    sep = re.split(pattern, doc)
    docs = [x for x in sep if x != None and len(x)>1]
    sentence_list = []
    for line in docs:
      sentence_list.append(line)

    return sentence_list

  def Cosine(self, question_vector, sentence_vector):
    dot_product = np.dot(question_vector, sentence_vector.T)
    denominator = (np.linalg.norm(question_vector) * np.linalg.norm(sentence_vector))
    return dot_product/denominator

  def similarity(self, ques, text):
    tfidf = TfidfVectorizer()
    sen_list = self.get_sentence(text)
    tfidf.fit(sen_list)
    s_vectors = tfidf.transform(sen_list)
    q_vectors = tfidf.transform([ques])
    cosine = self.Cosine(s_vectors.toarray(),q_vectors.toarray())
    sorted_index = cosine.argsort(axis=0)[::-1]

    return sen_list, sorted_index

  def output(self, ques, text):
    sen_list, sorted_index = self.similarity(ques, text)
    answer_text = sen_list[sorted_index[0][0]]
    return answer_text

'''
# top three sentences
  def output_H(self, ques, text):
    sen_list, sorted_index = self.similarity(ques, text)
    text = str()
    for j in range(3):
        text += (sen_list[sorted_index[j][0]] + '. ')
    return text
'''


"""# Binary Questions"""

class Binary():

  def get_noun(self, sentence):
    tag = []
    for word in sentence:
        if word.pos_ in ['NOUN', 'PROPN']:
            tag += [word.lemma_]
    return tag

  def yes_no(self, ques_text, sent_text):
    ques = nlp(ques_text)
    sent = nlp(sent_text)

    doc1_nouns = self.get_noun(ques)
    doc2_nouns = self.get_noun(sent)

    none_label = re.compile('not |n\'t|never|none|no ')

    # if
    if not doc1_nouns:
        return 'EMPTY'

    for word in doc1_nouns:
        if word in doc2_nouns:
            if (none_label.search(ques_text) and none_label.search(sent_text)) or (((none_label.search(ques_text) is None) and (none_label.search(ques_text) is None))):
                return 'Yes'
    return 'No'

def get_answer(ques_text, sent_text):
  if question_type(ques_text) == 'binary':
    tfidf = tfidf_sim()
    sentence = tfidf.output(ques_text,sent_text)
    binary = Binary()
    return binary.yes_no(ques_text, sentence)
  else:
    tfidf = tfidf_sim()
    return tfidf.output(ques_text,sent_text)

def main():
  question_path = sys.argv[2]
  context_path = sys.argv[1]
  with open(question_path, 'r', encoding = 'utf_8') as file:
    question = file.read().rstrip('\n')
  question_list = re.split('\n', question)
  with open(context_path, 'r', encoding = 'utf_8') as file:
    context = file.read().rstrip('\n')
  for ques in question_list:
    print(get_answer(ques, context).strip())
    # sys.stdout.write('\n'+ get_answer(ques, context).strip('\n').strip(' '))

if __name__ == '__main__':
  main()
